{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d90aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "def Softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True) \n",
    "                       #The summation is performed along the last axis of the array (axis=-1)\n",
    "                       #the reduced axis is kept as a dimension of size 1 (keepdims=True)\n",
    "                       #shape of (N,1) instead of (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc686be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer output: [[2.  0. ]\n",
      " [1.5 0. ]]\n",
      "second layer output: [[0.73105858 0.26894142]\n",
      " [0.62245933 0.37754067]]\n"
     ]
    }
   ],
   "source": [
    "X= np.array([[1, 1, 3], [1, 2, 2.5]])\n",
    "Y = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "### Initialization of Weights ###\n",
    "W1_0 = W2_0 = np.array([[-1,0], [0,-1], [1, 0]])\n",
    "\n",
    "### Forward Pass ###\n",
    "\n",
    "# first layer output\n",
    "L1=ReLU(X @ W1_0)\n",
    "print(\"first layer output:\", L1)\n",
    "\n",
    "# second layer output\n",
    "# Column of 1s (2x1)\n",
    "ones = np.ones((L1.shape[0], 1))\n",
    "# Concatenate along columns (axis=1)\n",
    "L1_with_ones = np.hstack((ones, L1))\n",
    "L2=Softmax(L1_with_ones @ W2_0)\n",
    "print(\"second layer output:\", L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c71a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at Second layer: [[-0.26894142  0.26894142]\n",
      " [ 0.62245933 -0.62245933]]\n",
      "Gradient at Second layer: [[ 0.17675895 -0.17675895]\n",
      " [ 0.19790308 -0.19790308]\n",
      " [ 0.          0.        ]]\n",
      "Weights update at Second layer: [[-1.0176759   0.0176759 ]\n",
      " [-0.01979031 -0.98020969]\n",
      " [ 1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "### Backward Pass ###\n",
    "\n",
    "# Error at Second layer\n",
    "E2 = L2-Y\n",
    "print(\"Error at Second layer:\", E2)\n",
    "# Gradient at Second layer\n",
    "G2 = (L1_with_ones.T @ E2)/X.shape[0]\n",
    "print(\"Gradient at Second layer:\", G2)\n",
    "# Weights update at Second layer\n",
    "W2_1 = W2_0 - 0.1 * G2\n",
    "print(\"Weights update at Second layer:\", W2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f11b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at First layer: [[-0.26894142 -0.        ]\n",
      " [ 0.62245933  0.        ]]\n",
      "Gradient at First layer: [[0.17675895 0.        ]\n",
      " [0.48798862 0.        ]\n",
      " [0.37466203 0.        ]]\n",
      "Weights update at First layer: [[-1.0176759   0.        ]\n",
      " [-0.04879886 -1.        ]\n",
      " [ 0.9625338   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Error at First layer\n",
    "E1 = E2 @ W2_0[1:].T * (L1 > 0) #(L1>0)=(Z1>0), which is the derivative of ReLU.\n",
    "print(\"Error at First layer:\", E1)\n",
    "# Gradient at First layer\n",
    "G1 = (X.T @ E1)/X.shape[0]\n",
    "print(\"Gradient at First layer:\", G1)\n",
    "# Weights update at First layer\n",
    "W1_1 = W1_0 - 0.1 * G1\n",
    "print(\"Weights update at First layer:\", W1_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee2213",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
